{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CrowdednessPrediction_Autoencoder_Nikos_noFigures.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Kg6ue36t6Qq6",
        "9aiLrurg7DVS",
        "gCokCekdi6GM"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg6ue36t6Qq6"
      },
      "source": [
        "# Data Loading and Transformation from Matrices to Link Counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "542v0KW5dwup"
      },
      "source": [
        "make sure to upload data (ie \"od-demand-202010-150.npy\", od_stop, od_time,etc) from local machine to google colab notebook instance by clicking on \"upload files\", on the left. They must be re-uploaded every time the notebook instance is closed and re-opened. However, it doesn't take a long time to transform all the data.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWQwVwildoND",
        "outputId": "cb889789-b7d1-44c3-9645-ff9dabbe909b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def load_data(fp = '', pickle = False):\n",
        "    data = np.load(fp, allow_pickle = pickle )\n",
        "    return data\n",
        "\n",
        "# def load_stop_data(fp=''):\n",
        "#     data = pickle.load(fp)\n",
        "#     return data\n",
        "\n",
        "def transform_matrix(matrix):\n",
        "    \"\"\"\n",
        "    Assuming matrix is 10x10\n",
        "    \"\"\"\n",
        "    link_counts = []\n",
        "    for i in range(len(matrix)-1):\n",
        "        sum = np.sum(matrix[0:i+1, i+1:])\n",
        "        link_counts.append(sum)\n",
        "\n",
        "    return link_counts\n",
        "\n",
        "def transform_all(matrices):\n",
        "    all_counts = []\n",
        "    for i in range(len(matrices)):\n",
        "        count = transform_matrix(matrices[i])\n",
        "        all_counts.append(count)\n",
        "    return all_counts\n",
        "    \n",
        "\n",
        "\n",
        "demand_matrices = load_data('od-150-1H-20201125-120-demand.npy')\n",
        "\n",
        "stop_names = load_data('od-150-1H-20201125-120-stop.npy', pickle = True)\n",
        "print(\"bus stops: \", stop_names[0:10])\n",
        "\n",
        "dates = load_data('od-150-1H-20201125-120-time.npy')\n",
        "dates.shape = [np.shape(dates)[0], 1]\n",
        "print(\"dimensions of date data: \", np.shape(dates))\n",
        "\n",
        "# Finally we transform the data from matrices to link counts\n",
        "route_counts = transform_all(demand_matrices)\n",
        "print(\"dimension of transformed matrices: \", np.shape(route_counts))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bus stops:  ['KDST' 'EGEV' 'HHLS' 'HHM' 'GLHO' 'NÃ†ST' 'KLBV' 'RYST' 'HKP' 'NPST']\n",
            "dimensions of date data:  (2904, 1)\n",
            "dimension of transformed matrices:  (2904, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aiLrurg7DVS"
      },
      "source": [
        "#Basic Plotting and Data Visualization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "fyqPwDSZ6xA7",
        "outputId": "f5d36569-12ea-4031-9616-98bf13306ad9"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def date_to_string(dates):\n",
        "    date = \"\"\n",
        "    new_dates = []\n",
        "    for d in dates:\n",
        "        date = str(d)[2:15]\n",
        "        new_dates.append(date)\n",
        "    return new_dates\n",
        "\n",
        "\n",
        "def transform_to_plot_data(route_counts, start, stop):\n",
        "    \"\"\" Transforms the route counts to a format that can be easily \n",
        "        plotted and visualized.\n",
        "        We create a time series of data (in 1 hour intervals) for each link.\n",
        "    \"\"\"\n",
        "    if not stop <= np.shape(route_counts)[0]:\n",
        "        print(\"Error- interval end longer than route count matrix\")\n",
        "        return -1\n",
        "\n",
        "    link_dict = {}\n",
        "    for i in range(np.shape(route_counts)[1]):\n",
        "        links = []\n",
        "        link_num = i+1\n",
        "\n",
        "        for j in range(start, stop):\n",
        "            links.append(route_counts[j][i])\n",
        "\n",
        "        link_dict[link_num] = links\n",
        "\n",
        "    return link_dict\n",
        "\n",
        "\n",
        "def plot_route_counts(route_counts, start, stop, links = range(len(route_counts[1])), plot_type = 'line'):\n",
        "    \"\"\"\n",
        "    Plot the counts at each link over a given time interval.\n",
        "    When entering in the links you wish to plot, subtract 1. \n",
        "    i.e. links = [0,1,2] if you wish to plot links 1, 2, 3.\n",
        "    It's just an indexing thing. \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    link_dict = transform_to_plot_data(route_counts, start, stop)\n",
        "    fig = plt.figure(figsize=(24,10))\n",
        "    \n",
        "    if plot_type == 'line':\n",
        "        for i in links:\n",
        "            plt.plot(dates[start:stop], link_dict[i+1], label='link'+str(i+1))\n",
        "    elif plot_type == 'bar':\n",
        "\n",
        "        for i in links:\n",
        "            plt.bar(list(np.arange(start, stop)), list(link_dict[i+1]))\n",
        "            plt.xticks(np.arange(start, stop), date_to_string(dates[start:stop]), rotation = 90)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "\n",
        "links = [0,1,2]\n",
        "plot_route_counts(route_counts, 5668, 5786, links)\n",
        "print(links)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error- interval end longer than route count matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6b00fe2d0fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mplot_route_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5668\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5786\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6b00fe2d0fd9>\u001b[0m in \u001b[0;36mplot_route_counts\u001b[0;34m(route_counts, start, stop, links, plot_type)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mplot_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1728x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCokCekdi6GM"
      },
      "source": [
        "#Data Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT4LZScDIJeC"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def shuffle_in_unison(X, Y):\n",
        "    n_elem = X.shape[0]\n",
        "    indeces = np.random.permutation(n_elem)\n",
        "    return X[indeces], Y[indeces]\n",
        "\n",
        "X = np.array(route_counts) \n",
        "# normalized_X = preprocessing.normalize(X)\n",
        "# Y = np.delete(normalized_X,0,0) # output is shifted by one row by deleting the first row\n",
        "# X = np.delete(normalized_X,normalized_X.shape[0]-1, 0) # delete the last input because it has no output\n",
        "# X_new = X\n",
        "# Y = np.delete(X_new,0,0) # output is shifted by one row by deleting the first row\n",
        "# X = np.delete(X_new,X_new.shape[0]-1, 0) # delete the last input because it has no output\n",
        "\n",
        "look_back = 20\n",
        "look_ahead = 8\n",
        "len_sequence = look_back\n",
        "batch_size = 100\n",
        "len_data = X.shape[0]\n",
        "data = []\n",
        "# create all possible sequences of length len_sequence\n",
        "for index in range(len_data - look_back - look_ahead): \n",
        "    data.append(X[index: index + look_back + look_ahead])\n",
        "data = np.array(data)\n",
        "X = data[:len_data,:look_back,:]\n",
        "Y = data[:len_data,-look_ahead:,:]\n",
        "\n",
        "num_features = X.shape[2]\n",
        "\n",
        "# X, Y = shuffle_in_unison(X, Y)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nu2aZdrfvB7",
        "outputId": "eb502dee-06c7-42df-ce77-f03f138b13f8"
      },
      "source": [
        "class Dataset():\n",
        "    def __init__(self, inputs, targets):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the size of the dataset\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Retrieve inputs and targets at the given index\n",
        "        X = self.inputs[index]\n",
        "        y = self.targets[index]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    \n",
        "def create_datasets(X, Y, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):\n",
        "    # Define partition sizes\n",
        "    num_train = int(len_data*p_train)\n",
        "    num_val = int(len_data*p_val)\n",
        "    num_test = int(len_data*p_test)\n",
        "\n",
        "    # Get inputs and targets for each partition\n",
        "    inputs_train, targets_train = X[:num_train], Y[:num_train]  \n",
        "    inputs_val, targets_val = X[num_train:num_train+num_val], Y[num_train:num_train+num_val]\n",
        "    inputs_test, targets_test = X[-num_test:], Y[-num_test:]\n",
        "\n",
        "    # Create datasets\n",
        "    training_set = dataset_class(inputs_train, targets_train)\n",
        "    validation_set = dataset_class(inputs_val, targets_val)\n",
        "    test_set = dataset_class(inputs_test, targets_test)\n",
        "\n",
        "    return training_set, validation_set, test_set\n",
        "\n",
        "\n",
        "training_set, validation_set, test_set = create_datasets(X, Y, Dataset)\n",
        "\n",
        "print(f'We have {len(training_set)} samples in the training set.')\n",
        "print(f'We have {len(validation_set)} samples in the validation set.')\n",
        "print(f'We have {len(test_set)} samples in the test set.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 2323 samples in the training set.\n",
            "We have 290 samples in the validation set.\n",
            "We have 290 samples in the test set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62QnCKtR-xWl"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "def load_dataset():\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "      dataset = training_set,\n",
        "      batch_size= batch_size,\n",
        "      num_workers = 0,\n",
        "      shuffle= False\n",
        "    )\n",
        "\n",
        "    validationloader = torch.utils.data.DataLoader(\n",
        "      dataset = validation_set,\n",
        "      batch_size= batch_size,\n",
        "      num_workers= 0,\n",
        "      shuffle= False\n",
        "    )\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "      dataset = test_set,\n",
        "      batch_size= batch_size,\n",
        "      num_workers= 0,\n",
        "      shuffle= False\n",
        "    )\n",
        "\n",
        "    return trainloader, validationloader, testloader\n",
        "\n",
        "trainloader, validationloader, testloader = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lzIOcjui_U7"
      },
      "source": [
        "#Network Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRu2dyrsiN10",
        "outputId": "c15cede4-6240-498a-cb37-10ad34de51c6"
      },
      "source": [
        "class lstm_encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
        "        \n",
        "        '''\n",
        "        : param input_size:     the number of features in the input X\n",
        "        : param hidden_size:    the number of features in the hidden state h\n",
        "        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n",
        "        :                       2 stacked LSTMs)\n",
        "        '''\n",
        "        \n",
        "        super(lstm_encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # define LSTM layer\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                            num_layers = num_layers, batch_first = True)\n",
        "\n",
        "    def forward(self, x_input):\n",
        "        \n",
        "        '''\n",
        "        : param x_input:               input of shape (seq_len, # in batch, input_size)\n",
        "        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence;\n",
        "        :                              hidden gives the hidden state and cell state for the last\n",
        "        :                              element in the sequence \n",
        "        '''\n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(x_input.view(x_input.shape[0], x_input.shape[1], self.input_size))\n",
        "        \n",
        "        return lstm_out, self.hidden     \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        \n",
        "        '''\n",
        "        initialize hidden state\n",
        "        : param batch_size:    x_input.shape[1]\n",
        "        : return:              zeroed hidden state and cell state \n",
        "        '''\n",
        "        \n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
        "\n",
        "\n",
        "class lstm_decoder(nn.Module):\n",
        "    ''' Decodes hidden state output by encoder '''\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
        "\n",
        "        '''\n",
        "        : param input_size:     the number of features in the input X\n",
        "        : param hidden_size:    the number of features in the hidden state h\n",
        "        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n",
        "        :                       2 stacked LSTMs)\n",
        "        '''\n",
        "        \n",
        "        super(lstm_decoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size,\n",
        "                            num_layers = num_layers, batch_first= True)\n",
        "        self.linear = nn.Linear(hidden_size, input_size)           \n",
        "\n",
        "    def forward(self, x_input, encoder_hidden_states):\n",
        "        \n",
        "        '''        \n",
        "        : param x_input:                    should be 2D (batch_size, input_size)\n",
        "        : param encoder_hidden_states:      hidden states\n",
        "        : return output, hidden:            output gives all the hidden states in the sequence;\n",
        "        :                                   hidden gives the hidden state and cell state for the last\n",
        "        :                                   element in the sequence \n",
        " \n",
        "        '''\n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(x_input, encoder_hidden_states)\n",
        "        output = self.linear(lstm_out)     \n",
        "        \n",
        "        return output, self.hidden\n",
        "\n",
        "\n",
        "\n",
        "class MyRecurrentNet(nn.Module):\n",
        "    def __init__(self, input_size, hidded_size):\n",
        "        super(MyRecurrentNet, self).__init__()\n",
        "        \n",
        "        # Recurrent layer\n",
        "        # YOUR CODE HERE!\n",
        "        # self.lstm = nn.LSTM(input_size=num_features,\n",
        "        #                  hidden_size=2*num_features,\n",
        "        #                  num_layers=2,\n",
        "        #                  bidirectional=False,\n",
        "        #                  batch_first = True,\n",
        "        #                  dropout = 0.6, )\n",
        "        # # Output layer\n",
        "        # self.l_out = nn.Linear(in_features=2*num_features,\n",
        "        #                     out_features=num_features,\n",
        "        #                     bias=False)\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = lstm_encoder(input_size = input_size, hidden_size = hidden_size)\n",
        "        self.decoder = lstm_decoder(input_size = input_size, hidden_size = hidden_size)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "    #     # RNN returns output and last hidden state\n",
        "    #     # print(len(x.size()))\n",
        "    #     # if len(x.size()) == 2:\n",
        "    #     #   batch_size = 1\n",
        "    #     # else:\n",
        "        batch_size = x.shape[0]     \n",
        "    #     # Flatten output for feed-forward layer\n",
        "    #     x = x.contiguous().view(-1, self.lstm.hidden_size)        \n",
        "    #     # Output layer\n",
        "    #     x = self.l_out(x)\n",
        "    #     x = torch.Tensor.reshape(x, (batch_size, len_sequence - 1, num_features))\n",
        "    #     x = x[:, -1, :]\n",
        "    #     return x\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(x)\n",
        "        # print(encoder_outputs.shape)\n",
        "        # print(x.shape)\n",
        "        # decoder_input = encoder_outputs[:,:,-num_features:]\n",
        "        decoder_input = x\n",
        "        # decoder_input = torch.zeros_like(x)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        outputs = torch.zeros(batch_size, look_ahead, num_features)\n",
        "        for hour in range(look_ahead):\n",
        "          decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "          # print(decoder_output.shape)\n",
        "          # x = torch.Tensor.reshape(decoder_output, (batch_size, num_features))\n",
        "          outputs[:, hour, :] = decoder_output[:, -1, :]\n",
        "          decoder_input = decoder_output\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "input_size = 9\n",
        "hidden_size = 30\n",
        "net = MyRecurrentNet(input_size, hidden_size)\n",
        "net = net.float()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyRecurrentNet(\n",
            "  (encoder): lstm_encoder(\n",
            "    (lstm): LSTM(9, 30, batch_first=True)\n",
            "  )\n",
            "  (decoder): lstm_decoder(\n",
            "    (lstm): LSTM(9, 30, batch_first=True)\n",
            "    (linear): Linear(in_features=30, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "_5b0Ezelicop",
        "outputId": "2acce3e3-5942-4405-b609-041ef1f40c5c"
      },
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 50\n",
        "input_size = 9\n",
        "hidden_size = 30\n",
        "look_ahead = 8\n",
        "\n",
        "\n",
        "# Initialize a new network\n",
        "net = MyRecurrentNet(input_size, hidden_size).cuda()\n",
        "\n",
        "# Define a loss function and optimizer for this problem\n",
        "# YOUR CODE HERE!\n",
        "criterion = nn.MSELoss()\n",
        "# criterion = nn.L1Loss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.006)\n",
        "\n",
        "# Track loss\n",
        "training_loss, validation_loss = [], []\n",
        "\n",
        "# For each epoch\n",
        "for i in range(num_epochs):\n",
        "    \n",
        "    # Track loss\n",
        "    epoch_training_loss = 0\n",
        "    epoch_validation_loss = 0\n",
        "    \n",
        "    net.eval()\n",
        "        \n",
        "    # For each sentence in validation set\n",
        "    for _,(inputs, targets) in enumerate(validationloader):\n",
        "        batch = inputs.shape[0]\n",
        "\n",
        "        inputs= inputs.float().cuda()\n",
        "        # print(inputs.shape)\n",
        "        targets = targets.float()\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        # Update loss\n",
        "        epoch_validation_loss += loss.detach().numpy() * batch\n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    # For each sentence in training set\n",
        "    for _,(inputs, targets) in enumerate(trainloader):\n",
        "        batch = inputs.shape[0]\n",
        "\n",
        "        inputs = inputs.float().cuda()\n",
        "        targets = targets.float()\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "        # Compute loss\n",
        "        # YOUR CODE HERE!\n",
        "        loss = criterion(outputs, targets)\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update loss\n",
        "        epoch_training_loss += loss.detach().numpy() * batch\n",
        "        \n",
        "    # Save loss for plot\n",
        "    training_loss.append(epoch_training_loss/len(training_set))\n",
        "    validation_loss.append(epoch_validation_loss/len(validation_set))\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if i % 10 == 0:\n",
        "        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n",
        "\n",
        "targets_test = []\n",
        "outputs_test = []\n",
        "# Get first sentence in test set\n",
        "for _,(inputs, targets) in enumerate(testloader):\n",
        "  inputs = inputs.float().cuda()\n",
        "  targets = targets.float()\n",
        "  targets_test = targets_test + targets.tolist()\n",
        "  # Forward pass\n",
        "  output = np.round(net.forward(inputs).data.numpy())\n",
        "  outputs_test = outputs_test + output.tolist()\n",
        "\n",
        "# Reduce the size to show better in plot\n",
        "MAX_HOURS = 200\n",
        "targets_test = targets_test[:MAX_HOURS]\n",
        "outputs_test = outputs_test[:MAX_HOURS]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(nrows=look_ahead, ncols=num_features, figsize=(9*30,8*30))\n",
        "# for h in range(look_ahead):\n",
        "#   for i in range(num_features):\n",
        "#     hour = np.arange(len(targets_test))\n",
        "#     title = stop_names[i] + \" - \" +stop_names[i+1] +\", hour: \"+str(h)\n",
        "#     axs[h, i].plot(hour, [link[:][h][i] for link in targets_test], 'r', label='Target values')\n",
        "#     axs[h, i].plot(hour, [link[:][h][i] for link in outputs_test], 'b', label='Predicted values')\n",
        "#     axs[h, i].legend()\n",
        "#     # axs[h, i].xlabel('Hour'), axs[0,i].ylabel('Passengers')\n",
        "#     axs[h, i].set_title(title)\n",
        "#     # plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "epoch = np.arange(len(training_loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
        "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch'), plt.ylabel('NLL')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, training loss: 1606.2567027268922, validation loss: 1784.5760834792566\n",
            "Epoch 10, training loss: 727.2085627778768, validation loss: 792.7360734610722\n",
            "Epoch 20, training loss: 625.8634163523562, validation loss: 660.1987388873922\n",
            "Epoch 30, training loss: 591.2411211320053, validation loss: 645.7596814385776\n",
            "Epoch 40, training loss: 544.8776428511674, validation loss: 572.4467562971444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}